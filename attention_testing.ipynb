{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention_testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw9OgUKv597B",
        "outputId": "219d57ea-f615-4769-9cb2-d6129204bbc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/sequences/sequences2')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import dataset_flickr7k\n",
        "import helper_classes as helper\n",
        "import nltk\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "nltk.download('punkt')\n",
        "\n",
        "import importlib \n",
        "#import model_attention as model_attn\n",
        "import model_attn_2 as model_attn\n",
        "importlib.reload(model_attn)\n",
        "\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zaudvfup6Gyn",
        "outputId": "9e69f068-0903-4951-f597-aeaa3c8055dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset\n",
        "data_args = {'stage': 'test',\n",
        "            'ds_path' : \"/content/drive/MyDrive/Colab Notebooks/sequences/sequences2\", \n",
        "            'captions_dir': \"\",\n",
        "            'captions_fname': 'results_new.csv',\n",
        "            'images_dir': '/images_split',\n",
        "            'freq_threshold': 5}\n",
        "\n",
        "test_data = dataset_flickr7k.Flickr7kData(**data_args)\n",
        "\n",
        "pad_idx = test_data.vocabulary.str_to_idx[\"<PAD>\"]\n",
        "\n",
        "test_loader = DataLoader(\n",
        "        dataset=test_data,\n",
        "        batch_size=  1,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNyV9wj26X9Y",
        "outputId": "7db7d664-5260-481b-eea7-a6ba6186a7ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length = 2000\n",
            "stage:  test\n",
            "ds_path:  /content/drive/MyDrive/Colab Notebooks/sequences/sequences2\n",
            "captions_f:  /content/drive/MyDrive/Colab Notebooks/sequences/sequences2/results_new.csv\n",
            "imgs_dir:  /content/drive/MyDrive/Colab Notebooks/sequences/sequences2/images_split/test\n",
            "Initialized 7736 words in vocabulary\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model for inference \n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "attn_dim = 256 \n",
        "num_layers = 1\n",
        "vocab_size = len(test_data.vocabulary)\n",
        "\n",
        "test_model = model_attn.EncodertoDecoder(embed_size, hidden_size, num_layers, vocab_size, attn_dim).to(device)\n",
        "helper.load_model(test_model, \"attention_model.pth\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jwqjmmIG6Y0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model.eval()\n",
        "# Test bleu score for one sample\n",
        "idx, X, y= next(iter(test_loader))\n",
        "X = X.to(device)\n",
        "features = test_model.encoder(X)\n",
        "\n",
        "captions = test_data.get_all_captions(idx.item())\n",
        "print(captions)\n",
        "longest_caption = max(captions, key=len)\n",
        "len_ref = len(longest_caption)\n",
        "\n",
        "predicted = test_model.generate_caption(features, test_data.vocabulary, len_ref)\n",
        "print(predicted)\n",
        "\n",
        "score = helper.get_bleu_4_score(captions, predicted)\n",
        "print(score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqlKy7DtFdm_",
        "outputId": "8792bdcf-36b6-4c54-c897-ac4db2b65028"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Two people are scuba diving in blue water with lots of bubbles .', 'Two people are scuba diving in the blue ocean .', 'Two individuals underwater scuba diving .', 'Two scuba divers are diving underwater .', 'Three people scuba dive under the sea .']\n",
            "a scuba diver underwater with a scuba diver in the background .\n",
            "0.6336760152247436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Bleu score\n",
        "\n",
        "score_total = 0\n",
        "\n",
        "for batch_num, (idx, X, y) in enumerate(test_loader):\n",
        "    X = X.to(device)\n",
        "    features = test_model.encoder(X)\n",
        "\n",
        "    captions = test_data.get_all_captions(idx.item())\n",
        "\n",
        "    longest_caption = max(captions, key=len)\n",
        "    len_ref = len(longest_caption)\n",
        "\n",
        "    predicted = test_model.generate_caption(features, test_data.vocabulary, len_ref)\n",
        "\n",
        "    score = helper.get_bleu_4_score(captions, predicted)\n",
        "    score_total += score\n",
        "\n",
        "\n",
        "    if batch_num%1000 == 0:\n",
        "        average = score_total/(batch_num+1)\n",
        "        print(f\"Batch # {batch_num}. Bleu Score Average: {average}\")\n",
        "\n",
        "print(f\"Batch # {batch_num}. Bleu Score Average: {average}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JCjADRh8Lw0",
        "outputId": "640cf233-9a09-4abd-99c7-df3bf58aedf4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch # 0. Bleu Score Average: 0.609792576406699\n",
            "Batch # 1000. Bleu Score Average: 0.5638946748982708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch # 2000. Bleu Score Average: 0.5576950493740349\n",
            "Batch # 3000. Bleu Score Average: 0.5588514572488127\n",
            "Batch # 4000. Bleu Score Average: 0.5578051312406589\n",
            "Batch # 5000. Bleu Score Average: 0.5582414972505214\n",
            "Batch # 6000. Bleu Score Average: 0.5591174720384869\n",
            "Batch # 7000. Bleu Score Average: 0.5594387188277306\n",
            "Batch # 8000. Bleu Score Average: 0.5593375138182385\n",
            "Batch # 9000. Bleu Score Average: 0.5587866488934441\n",
            "Batch # 9999. Bleu Score Average: 0.5587866488934441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up variables for loss calculation\n",
        "test_loader_128 = DataLoader(\n",
        "        dataset=test_data,\n",
        "        batch_size=  128,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=test_data.vocabulary.str_to_idx[\"<PAD>\"])"
      ],
      "metadata": {
        "id": "DijhrYl2-Sb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_loss = 0\n",
        "\n",
        "# for batch_num, (idx, X, y) in enumerate(test_loader_128):\n",
        "#     X = X.to(device)\n",
        "#     y = y.to(device)\n",
        "\n",
        "#     y_train = y.to(device)\n",
        "#     outputs = test_model(X, y_train)\n",
        "#     y_target = y[:, 1:].to(device)\n",
        "    \n",
        "#     loss = criterion(\n",
        "#         outputs.reshape(-1, outputs.shape[2]), \n",
        "#         y_target.reshape(-1)\n",
        "#     )\n",
        "    \n",
        "#     batch_loss += loss.item()\n",
        "\n",
        "# avg_batch_loss = batch_loss/(batch_num+1)\n",
        "\n",
        "# print(f'Average loss: {avg_batch_loss}')"
      ],
      "metadata": {
        "id": "Vhc_Bpt8-XrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vEdYKVuyBFMQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}