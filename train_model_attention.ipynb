{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avA4_tExC8p_",
        "outputId": "fbdfb5f8-6132-4bc6-abd8-c8aa95e21e5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/sequences/sequences2')"
      ],
      "id": "avA4_tExC8p_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59ef23ae-ffd8-49e4-9600-89b3cd1545a1",
        "outputId": "487e1ad0-c5f8-4801-f6b5-dbc6b3857b3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import dataset_flickr\n",
        "import dataset_flickr7k\n",
        "import helper_classes as helper\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils import data as data\n",
        "\n",
        "import time \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pathlib\n",
        "\n",
        "import os "
      ],
      "id": "59ef23ae-ffd8-49e4-9600-89b3cd1545a1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7901469e-f468-45c8-a3a8-476d217db4a4"
      },
      "outputs": [],
      "source": [
        "CHECKPOINT_DIRECTORY = \"model_checkpoints\""
      ],
      "id": "7901469e-f468-45c8-a3a8-476d217db4a4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cafd18b8-b7f3-4611-b8bb-d7f2538ac194"
      },
      "source": [
        "# Load Dataset"
      ],
      "id": "cafd18b8-b7f3-4611-b8bb-d7f2538ac194"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e2bfcfc-61cf-4d21-b76e-12921864fdfd"
      },
      "source": [
        "## Train set "
      ],
      "id": "6e2bfcfc-61cf-4d21-b76e-12921864fdfd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf17316c-4306-4804-a985-080e65132d8b",
        "outputId": "54527f09-a929-429b-940d-5ff15f1fe373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length = 6999\n",
            "stage:  train\n",
            "ds_path:  /content/drive/MyDrive/Colab Notebooks/sequences/sequences2\n",
            "captions_f:  /content/drive/MyDrive/Colab Notebooks/sequences/sequences2/results_new.csv\n",
            "imgs_dir:  /content/drive/MyDrive/Colab Notebooks/sequences/sequences2/images_split/train\n",
            "Initialized 7736 words in vocabulary\n",
            "Initialized 34995 images!\n"
          ]
        }
      ],
      "source": [
        "import importlib \n",
        "importlib.reload(dataset_flickr7k)\n",
        "# dataset\n",
        "data_args = {'stage': 'train',\n",
        "            'ds_path' : \"/content/drive/MyDrive/Colab Notebooks/sequences/sequences2\", \n",
        "            'captions_dir': \"\",\n",
        "            'captions_fname': 'results_new.csv',\n",
        "            'images_dir': '/images_split',\n",
        "            'freq_threshold': 5}\n",
        "#train_data = dataset_flickr.Flickr30kData(**data_args)\n",
        "train_data = dataset_flickr7k.Flickr7kData(**data_args)\n",
        "\n",
        "print(f\"Initialized {len(train_data)} images!\") "
      ],
      "id": "cf17316c-4306-4804-a985-080e65132d8b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3ec81d1-2ee8-46e1-a4c1-0f6cb74dba39"
      },
      "source": [
        "## Validation set"
      ],
      "id": "b3ec81d1-2ee8-46e1-a4c1-0f6cb74dba39"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86a858b3-b8ad-41b9-ab56-cb2ec047929c",
        "outputId": "ae7cc02f-3428-445d-c9c0-ca65cd8f540d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length = 1000\n",
            "stage:  val\n",
            "ds_path:  /content/drive/MyDrive/Colab Notebooks/sequences/sequences2\n",
            "captions_f:  /content/drive/MyDrive/Colab Notebooks/sequences/sequences2/results_new.csv\n",
            "imgs_dir:  /content/drive/MyDrive/Colab Notebooks/sequences/sequences2/images_split/val\n",
            "Initialized 7736 words in vocabulary\n",
            "Initialized 5000 images!\n"
          ]
        }
      ],
      "source": [
        "# dataset\n",
        "data_args = {'stage': 'val',\n",
        "            'ds_path' : \"/content/drive/MyDrive/Colab Notebooks/sequences/sequences2\", \n",
        "            'captions_dir': \"\",\n",
        "            'captions_fname': 'results_new.csv',\n",
        "            'images_dir': '/images_split',\n",
        "            'freq_threshold': 5}\n",
        "#val_data = dataset_flickr.Flickr30kData(**data_args)\n",
        "val_data = dataset_flickr7k.Flickr7kData(**data_args)\n",
        "\n",
        "print(f\"Initialized {len(val_data)} images!\") "
      ],
      "id": "86a858b3-b8ad-41b9-ab56-cb2ec047929c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5793dbfa-59e8-4ac0-803d-dec56696d361"
      },
      "source": [
        "## Test set"
      ],
      "id": "5793dbfa-59e8-4ac0-803d-dec56696d361"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "748d2af7-663e-48d8-9c21-fc9e4eb30bdc",
        "outputId": "67f78f02-0beb-479b-c8c6-a11eebed42f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length = 2000\n",
            "stage:  test\n",
            "ds_path:  /content/drive/MyDrive/Colab Notebooks/sequences/sequences2\n",
            "captions_f:  /content/drive/MyDrive/Colab Notebooks/sequences/sequences2/results_new.csv\n",
            "imgs_dir:  /content/drive/MyDrive/Colab Notebooks/sequences/sequences2/images_split/test\n",
            "Initialized 7736 words in vocabulary\n",
            "Initialized 10000 images!\n"
          ]
        }
      ],
      "source": [
        "# dataset\n",
        "data_args = {'stage': 'test',\n",
        "            'ds_path' : \"/content/drive/MyDrive/Colab Notebooks/sequences/sequences2\", \n",
        "            'captions_dir': \"\",\n",
        "            'captions_fname': 'results_new.csv',\n",
        "            'images_dir': '/images_split',\n",
        "            'freq_threshold': 5}\n",
        "#test_data = dataset_flickr.Flickr30kData(**data_args)\n",
        "test_data = dataset_flickr7k.Flickr7kData(**data_args)\n",
        "\n",
        "print(f\"Initialized {len(test_data)} images!\") "
      ],
      "id": "748d2af7-663e-48d8-9c21-fc9e4eb30bdc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aca5677e-231c-4306-b344-c8271a0cb5e3"
      },
      "source": [
        "## Set up data loader"
      ],
      "id": "aca5677e-231c-4306-b344-c8271a0cb5e3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c59ec99-699c-4c05-9ee7-a29de53c96dd"
      },
      "outputs": [],
      "source": [
        "pad_idx = train_data.vocabulary.str_to_idx[\"<PAD>\"]\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(\n",
        "        dataset=train_data,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=helper.CollateCustom(pad_idx),\n",
        "    )\n",
        "\n",
        "\n",
        "val_loader = DataLoader (\n",
        "        dataset=val_data,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=helper.CollateCustom(pad_idx),\n",
        "    )\n",
        "\n",
        "\n",
        "test_loader = DataLoader(\n",
        "        dataset=test_data,\n",
        "        batch_size=  1,\n",
        "        shuffle=True,\n",
        "    )\n"
      ],
      "id": "4c59ec99-699c-4c05-9ee7-a29de53c96dd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f8b2d37-3de9-453f-9835-3d56ffaa7b77",
        "outputId": "ce241484-8bb1-4e1d-c3e2-2de5041583d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "id": "2f8b2d37-3de9-453f-9835-3d56ffaa7b77"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7HDCsOE1rqr"
      },
      "source": [
        "# Attention\n"
      ],
      "id": "p7HDCsOE1rqr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31287546-cae0-48f1-b675-b20e12447584"
      },
      "source": [
        "## Set up hyperparameters"
      ],
      "id": "31287546-cae0-48f1-b675-b20e12447584"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1743ba45-c53b-45d8-9d26-466d0b3adca8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "TODO:\n",
        "- need to figure out train/val batch size \n",
        "- caption length - how to set this param? \n",
        "\"\"\"\n",
        "# Hyperparameters\n",
        "embed_size = 256\n",
        "hidden_size = 512 #256\n",
        "attn_dim = 256 \n",
        "vocab_size = len(train_data.vocabulary) #len(train_data.vocabulary)\n",
        "num_layers = 1\n",
        "\n",
        "learning_rate = 3e-4"
      ],
      "id": "1743ba45-c53b-45d8-9d26-466d0b3adca8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5220663c-d28d-4c40-b7b6-b693b6bede9d"
      },
      "source": [
        "## Initialize Model, Loss & optimizer"
      ],
      "id": "5220663c-d28d-4c40-b7b6-b693b6bede9d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e37f3d7f-cf36-4574-9212-5c85de4e3a83",
        "outputId": "016b4ad9-c302-4266-9714-192c9b70cf82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'model_attn_2' from '/content/drive/MyDrive/Colab Notebooks/sequences/sequences2/model_attn_2.py'>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import importlib \n",
        "#import model_attention as model_attn\n",
        "import model_attn_2 as model_attn\n",
        "importlib.reload(model_attn)"
      ],
      "id": "e37f3d7f-cf36-4574-9212-5c85de4e3a83"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f03012dc-e653-473c-b2cb-00d4d3bf7406",
        "outputId": "635ce3ba-6576-48f3-8568-e3f65170f6ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized Encoder!\n",
            "Initialized Decoder!\n"
          ]
        }
      ],
      "source": [
        "model = model_attn.EncodertoDecoder(embed_size, hidden_size, num_layers, vocab_size, attn_dim).to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=train_data.vocabulary.str_to_idx[\"<PAD>\"])\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "id": "f03012dc-e653-473c-b2cb-00d4d3bf7406"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "037580db-db3a-4460-9723-ae9126abad63"
      },
      "outputs": [],
      "source": [
        "idx, X, y= next(iter(train_loader))"
      ],
      "id": "037580db-db3a-4460-9723-ae9126abad63"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e434ca79-295a-4eff-a49b-3c1d38e41cce"
      },
      "source": [
        "## Train model"
      ],
      "id": "e434ca79-295a-4eff-a49b-3c1d38e41cce"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSqa2Zjb165r"
      },
      "source": [
        ""
      ],
      "id": "OSqa2Zjb165r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1ff3267-b774-405b-8380-cea752162718",
        "outputId": "bdffdd51-9b7f-4d4b-acfd-1c3b01e1273f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss after 1 epochs: 4.454128265380859\n",
            "Validation loss after 1 epochs: 4.163434028625488\n",
            "Training loss after 2 epochs: 4.029056072235107\n",
            "Validation loss after 2 epochs: 3.9817214012145996\n",
            "Training loss after 3 epochs: 3.811450719833374\n",
            "Validation loss after 3 epochs: 3.291828155517578\n",
            "Training loss after 4 epochs: 3.506115198135376\n",
            "Validation loss after 4 epochs: 3.761847972869873\n",
            "Training loss after 5 epochs: 3.4453299045562744\n",
            "Validation loss after 5 epochs: 3.5294666290283203\n",
            "Time elapsed: 41.97 min\n",
            "Saved checkpoint attention_model_5_epochs.pth!\n",
            "Training loss after 6 epochs: 3.3046748638153076\n",
            "Validation loss after 6 epochs: 3.380574941635132\n",
            "Training loss after 7 epochs: 3.3923192024230957\n",
            "Validation loss after 7 epochs: 3.1649856567382812\n",
            "Training loss after 8 epochs: 3.3166940212249756\n",
            "Validation loss after 8 epochs: 3.3842973709106445\n",
            "Training loss after 9 epochs: 3.0870521068573\n",
            "Validation loss after 9 epochs: 3.5726006031036377\n",
            "Training loss after 10 epochs: 3.1954686641693115\n",
            "Validation loss after 10 epochs: 3.329319715499878\n",
            "Time elapsed: 81.96 min\n",
            "Saved checkpoint attention_model_10_epochs.pth!\n",
            "Training loss after 11 epochs: 2.872232675552368\n",
            "Validation loss after 11 epochs: 2.7495007514953613\n",
            "Training loss after 12 epochs: 2.9750382900238037\n",
            "Validation loss after 12 epochs: 4.066125392913818\n",
            "Early Stopping Trigger Count:  1\n",
            "Training loss after 13 epochs: 2.9792630672454834\n",
            "Validation loss after 13 epochs: 3.17921781539917\n",
            "Training loss after 14 epochs: 2.8324577808380127\n",
            "Validation loss after 14 epochs: 2.7972750663757324\n",
            "Training loss after 15 epochs: 2.9171688556671143\n",
            "Validation loss after 15 epochs: 3.6364636421203613\n",
            "Time elapsed: 121.95 min\n",
            "Saved checkpoint attention_model_15_epochs.pth!\n",
            "Early Stopping Trigger Count:  2\n",
            "Training loss after 16 epochs: 2.83569073677063\n",
            "Validation loss after 16 epochs: 4.225852966308594\n",
            "Early Stopping Trigger Count:  3\n",
            "Saved model basic_model.pth!\n",
            "Early Stopping!\n",
            "Time elapsed for 30 epochs: 130.0 min\n",
            "loss:  2.83569073677063\n"
          ]
        }
      ],
      "source": [
        "#import pathlib\n",
        "CHECKPOINT_DIRECTORY = \"/content/drive/MyDrive/Colab Notebooks/sequences/sequences2/model_checkpoints\"\n",
        "\n",
        "model.train()\n",
        "\n",
        "start = 1\n",
        "num_epochs = 30  #60 #ONLY USE MULTIPLES OF 10 \n",
        "losses = [] \n",
        "losses_val = []\n",
        "\n",
        "time_start = time.time() \n",
        "\n",
        "restore_latest_checkpoint = False\n",
        "\n",
        "if restore_latest_checkpoint:\n",
        "    #find last checkpoint file based on last modified \n",
        "    all_files = pathlib.Path(CHECKPOINT_DIRECTORY).glob('*.pth')\n",
        "    latest_file = max(all_files, key=os.path.getctime)\n",
        "    checkpoint_file = str(latest_file).split(\"/\")[1]\n",
        "    \n",
        "    #adjust epoch range\n",
        "    start = int(checkpoint_file.split(\"_\")[2]) + 1 \n",
        "    num_epochs += start \n",
        "    \n",
        "    #load checkpoint \n",
        "    helper.load_checkpoint(checkpoint_file, model, optimizer)\n",
        "\n",
        "\"\"\"\n",
        "Training\n",
        "\"\"\"\n",
        "# Early stopping variables\n",
        "previous_loss = 50\n",
        "triggered = 0\n",
        "\n",
        "for epoch in range(start, num_epochs+1):\n",
        "\n",
        "\n",
        "    batch_loss = 0 \n",
        "    avg_batch_loss = 0 \n",
        "    \n",
        "    for batch_num, (idx, X, y) in enumerate(train_loader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        y_train = y.to(device)\n",
        "        outputs = model(X, y_train)\n",
        "        y_target = y[:, 1:].to(device)\n",
        "        \n",
        "        loss = criterion(\n",
        "            outputs.reshape(-1, outputs.shape[2]), \n",
        "            y_target.reshape(-1)\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_loss += loss.item()\n",
        "        \n",
        "        # if batch_num %100 == 0:\n",
        "        #     print(f\"batch : {batch_num}, loss : {loss.item()}\")\n",
        "            \n",
        "        #     \"\"\"show sample caption\"\"\"\n",
        "        #     model.eval()\n",
        "        #     with torch.no_grad():\n",
        "        #         idx, images, captions= next(iter(train_loader))\n",
        "        #         images = images.to(device)\n",
        "        #         features = model.encoder(images[0:1])\n",
        "        #         plt.imshow(train_data.plot_img(idx[0]))\n",
        "\n",
        "        #         # print(\"Expected: \", train_data.get_image_caption(idx[0]))\n",
        "        #         # print(\"Predicted: \", model.generate_caption(features, train_data.vocabulary, 20))\n",
        "        #     model.train()\n",
        "\n",
        "    #save loss after every epoch \n",
        "    avg_batch_loss = batch_loss/(batch_num+1)\n",
        "    \n",
        "        \n",
        "    \"\"\"\n",
        "    Validation\n",
        "    \"\"\"\n",
        "    # run validation set to see find loss \n",
        "    batch_loss_val = 0 \n",
        "    avg_batch_loss_val = 0 \n",
        "    with torch.no_grad(): \n",
        "        #UNCOMMENT THIS \n",
        "        for batch_num_val, (idx_val, X_val, y_val) in enumerate(val_loader):\n",
        "            X_val = X_val.to(device)\n",
        "            y_val = y_val.to(device)\n",
        "            \n",
        "            #skip eos (?) \n",
        "            y_train_val = y_val.to(device)\n",
        "\n",
        "            #calculate loss\n",
        "            out_val = model(X_val, y_train_val)\n",
        "            #skip sos for target \n",
        "            y_val_target = y_val[:, 1:].to(device)\n",
        "            \n",
        "            loss_val = criterion(out_val.reshape(-1, out_val.shape[2]), y_val_target.reshape(-1))\n",
        "            \n",
        "            batch_loss_val += loss_val.item()\n",
        "\n",
        "    #losses_val.append(loss_val.item())#{epoch : loss_val.item()})\n",
        "    avg_batch_loss_val = batch_loss_val/(batch_num_val+1)\n",
        "\n",
        "    losses.append([avg_batch_loss, avg_batch_loss_val])\n",
        "\n",
        "\n",
        "    print(f\"Training loss after {epoch} epochs: {loss.item()}\\nValidation loss after {epoch} epochs: {loss_val.item()}\")\n",
        "    \n",
        "    \"\"\"\n",
        "    Save checkpoints\n",
        "    \"\"\" \n",
        "    if epoch%5 == 0:\n",
        "        print(\"Time elapsed: {} min\".format((round((time.time()-time_start)/60, 2))))\n",
        "        #save checkpoint \n",
        "        checkpoint = {\"state_dict\": model.state_dict(),\n",
        "                    \"optimizer\": optimizer.state_dict(),\n",
        "                    \"step\": epoch\n",
        "                    }\n",
        "        fname = \"attention_model_\" + str(epoch) + \"_epochs.pth\"\n",
        "        \n",
        "        #UNCOMMENT THIS \n",
        "        helper.save_checkpoint(checkpoint, fname)\n",
        "        \n",
        "    \"\"\"    \n",
        "    Early stopping\n",
        "    \"\"\"\n",
        "    current_loss = avg_batch_loss_val\n",
        "\n",
        "    if current_loss > previous_loss:\n",
        "        triggered += 1\n",
        "        print('Early Stopping Trigger Count: ', triggered)\n",
        "\n",
        "        if triggered >= 3:\n",
        "            helper.save_model(model.state_dict(), \"basic_model.pth\")\n",
        "            print('Early Stopping!')\n",
        "            break;\n",
        "\n",
        "    previous_loss = current_loss    \n",
        "        \n",
        "                \n",
        "    #for final epoch \n",
        "    if epoch == num_epochs: \n",
        "        helper.save_model(model.state_dict(), \"attention_model.pth\")\n",
        "             \n",
        "print(\"Time elapsed for {} epochs: {} min\".format(epoch, \n",
        "                                                  round((time.time()-time_start)/60, 2)))\n",
        "print(\"loss: \", loss.item())"
      ],
      "id": "f1ff3267-b774-405b-8380-cea752162718"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceb8c7b3-5a7f-468b-b8b3-23b93e385e2d"
      },
      "source": [
        "## Plot loss "
      ],
      "id": "ceb8c7b3-5a7f-468b-b8b3-23b93e385e2d"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "b994380c-aa85-4509-bba9-43a452b78039",
        "outputId": "56e9aa57-6bc9-4a45-c984-ea4dd8ca8694"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f29d9eab590>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "import pandas as pd\n",
        "sns.set() \n",
        "\n",
        "\n",
        "if restore_latest_checkpoint: \n",
        "    #add to existing losses \n",
        "    old_losses = pd.read_csv('loss.csv')[[\"epochs\", \"loss\", \"loss_val\"]]\n",
        "    start_index = old_losses.epochs.max() + 1\n",
        "    new_data = [[start_index+i, losses[i][0], losses[i][1]] for i in range(len(losses))]\n",
        "    new_losses = pd.DataFrame(new_data, columns = [\"epochs\", \"loss\", \"loss_val\"])\n",
        "    loss_df = pd.concat([old_losses, new_losses], keys = [\"epochs\", \"loss\", \"loss_val\"]).reset_index(drop = True)\n",
        "    \n",
        "else:\n",
        "    #create new df \n",
        "    loss_df = pd.DataFrame(losses, columns = ['loss', \"loss_val\"])\n",
        "    loss_df = loss_df.reset_index().rename(columns= {'index': 'epochs'})\n",
        "    \n",
        "loss_df.to_csv(\"loss.csv\")\n",
        "\n",
        "loss_df\n",
        "sns.lineplot(data= loss_df.iloc[:, 1:])\n",
        "#sns.lineplot(data = loss_df, x = \"epochs\", y = \"loss\") "
      ],
      "id": "b994380c-aa85-4509-bba9-43a452b78039"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef2b5294-291d-41eb-ac25-a748bfade045"
      },
      "source": [
        "## Test random cases"
      ],
      "id": "ef2b5294-291d-41eb-ac25-a748bfade045"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1abbbd98-fa61-4d7f-9116-f37a85e2ae5d"
      },
      "outputs": [],
      "source": [
        "#import model \n",
        "#find last checkpoint file based on last modified \n",
        "all_files = pathlib.Path(CHECKPOINT_DIRECTORY).glob('*.pth')\n",
        "latest_file = max(all_files, key=os.path.getctime)\n",
        "checkpoint_file = str(latest_file).split(\"/\")[1]\n",
        "\n",
        "#print(checkpoint_file)\n",
        "\n",
        "model = model_attn.EncodertoDecoder(embed_size, hidden_size, num_layers, vocab_size).to(device)\n",
        "\n",
        "path =  CHECKPOINT_DIRECTORY + \"/\" +  checkpoint_file\n",
        "checkpoint = torch.load(path)\n",
        "model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "model.eval()\n",
        "None"
      ],
      "id": "1abbbd98-fa61-4d7f-9116-f37a85e2ae5d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "597464ca-9649-4d5a-b76a-cb0bf9c1b547"
      },
      "outputs": [],
      "source": [
        "#Load model for inference \n",
        "#import model\n",
        "#model = model.EncodertoDecoder(embed_size, hidden_size, num_layers, vocab_size, extract_features).to(device)\n",
        "#helper.load_model(model, \"basic_model.pth\")\n",
        "\n",
        "#basic_model_170_epochs.pth\n",
        "\n",
        "#model.eval()\n",
        "#None"
      ],
      "id": "597464ca-9649-4d5a-b76a-cb0bf9c1b547"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a3d0bcdc-8a0d-4ae6-a5cd-7cc13b75a084"
      },
      "outputs": [],
      "source": [
        "idx, X, y= next(iter(test_loader))"
      ],
      "id": "a3d0bcdc-8a0d-4ae6-a5cd-7cc13b75a084"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3eb15149-925d-40be-8027-1eba84b29455"
      },
      "outputs": [],
      "source": [
        "X = X.to(device)\n",
        "features = model.encoder(X)#.to(device)\n",
        "plt.imshow(test_data.plot_img(idx.item()))\n",
        "print(\"Expected: \", test_data.get_image_caption(idx.item()))\n",
        "print(\"Predicted: \", model.generate_caption(features, test_data.vocabulary, 20))"
      ],
      "id": "3eb15149-925d-40be-8027-1eba84b29455"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "729d692a-8c6e-43ea-93c7-033708463f59"
      },
      "outputs": [],
      "source": [
        "#train_data.plot_img(idx[0])\n",
        "plt.imshow(test_data.plot_img(idx.item()))\n",
        "print(\"Expected: \", test_data.get_image_caption(idx.item()))\n",
        "print(\"Predicted: \", model.caption_image_greedy(X.to(device), test_data.vocabulary, 20))"
      ],
      "id": "729d692a-8c6e-43ea-93c7-033708463f59"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2d46ca9f-c1ce-4c1f-868f-2a5c8e7570ef"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "TODO: when calculating score, compare to any of the reference sentence?\n",
        "\"\"\"\n",
        "#print(\"Expected: \", train_data.get_all_captions(idx[0]))\n",
        "#print(\"Predicted: \", model.caption_image(X[:1].to(device), train_data.vocabulary))\n",
        "\n",
        "\n",
        "print(\"Expected: \", test_data.get_image_caption(idx.item()))\n",
        "print(\"Predicted: \", model.caption_image_greedy(X.to(device), test_data.vocabulary, 20))"
      ],
      "id": "2d46ca9f-c1ce-4c1f-868f-2a5c8e7570ef"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "99a536f9-3127-4788-b549-06ed7122237d"
      },
      "outputs": [],
      "source": [
        "test_data.vocabulary.str_to_idx[\"<EOS>\"]"
      ],
      "id": "99a536f9-3127-4788-b549-06ed7122237d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d19b2021-aaf2-4ae4-9158-40ab74a71dcb"
      },
      "outputs": [],
      "source": [
        "from PIL import Image as PILImage\n",
        "\n",
        "fname = test_data.img_files_dict[idx.item()]\n",
        "path = test_data.imgs_dir + '/' + fname \n",
        "img = PILImage.open(path).convert('RGB')"
      ],
      "id": "d19b2021-aaf2-4ae4-9158-40ab74a71dcb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "094fdfee-c783-4544-94e6-b9ba7a27d7e0"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms as transforms\n",
        "\n",
        "transform_train = transforms.Compose([ \n",
        "                transforms.Resize(256),                          # smaller edge of image resized to 256\n",
        "               # transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
        "                transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
        "                transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
        "                transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
        "                                     (0.229, 0.224, 0.225))\n",
        "]\n",
        "            )\n",
        "img = transform_train(img)"
      ],
      "id": "094fdfee-c783-4544-94e6-b9ba7a27d7e0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fd21f612-e9c6-4892-9ccf-01b190764002"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "                transforms.Resize((299, 299)),\n",
        "                transforms.ToTensor()\n",
        "                #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "img = transform(img)"
      ],
      "id": "fd21f612-e9c6-4892-9ccf-01b190764002"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7b44f25d-ebde-4fc5-bce8-6095b48bd020"
      },
      "outputs": [],
      "source": [
        "# define a transform to convert a tensor to PIL image\n",
        "transform = transforms.ToPILImage()\n",
        "\n",
        "# convert the tensor to PIL image using above transform\n",
        "my_img= transform(img)\n",
        "\n",
        "# display the PIL image\n",
        "my_img.show()"
      ],
      "id": "7b44f25d-ebde-4fc5-bce8-6095b48bd020"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b31bf3ab-d23c-4038-8ee4-ff58126a8659"
      },
      "outputs": [],
      "source": [
        "print(idx[0])\n",
        "print(train_data.get_image_caption(idx[0]))\n",
        "print(train_data.get_all_captions(idx[0]))\n",
        "print(train_data.get_vectorized_caption(idx[0]))\n",
        "train_data.plot_img(idx[0])"
      ],
      "id": "b31bf3ab-d23c-4038-8ee4-ff58126a8659"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "train_model_attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}